{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEBGouCO6m2"
      },
      "source": [
        "# TD 3 : Entrainer un réseau de neurones basique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installation\n",
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ],
      "metadata": {
        "id": "Ky3Ge3YwO8Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce TD, vous allez définir puis entrainer un réseau de neurones très basique capable de reconnaitre les nombres de 0 à 9.\n",
        "\n",
        "Pour cela, nous allons utiliser le dataset MNIST. MNIST est un petit dataset contenant des chiffres manuscrits."
      ],
      "metadata": {
        "id": "hQOBC7c2PGY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLSCoBouO6m4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout d'abord, nous avons besoin de définir quelques outils utiles. Une classe `MNIST_dataset` pour interpréter les données de MNIST comme des tensors pytorch et une fonction `show_elem` pour afficher à l'écran un tensor donné."
      ],
      "metadata": {
        "id": "D0oZo37OS6rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, base_data):\n",
        "        self.base_data = base_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.base_data[idx]\n",
        "        img = torch.FloatTensor(np.array(img)) / 255\n",
        "        return img.view(1, 28, 28), label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_data)\n",
        "\n",
        "def show_elem(in_item):\n",
        "    N, H, L = in_item.size()\n",
        "    s = 112\n",
        "    in_item*=255\n",
        "    out = np.zeros((s, s*N), dtype='uint8')\n",
        "    for n in range(N):\n",
        "        x = torch.clamp(in_item[n], 0, 255)\n",
        "        x = x.detach().numpy().astype(np.uint8)\n",
        "        im = Image.fromarray(x)\n",
        "        im = im.resize((s, s), resample=0)\n",
        "        out[:, s*n:(n+1)*s] = np.asarray(im)\n",
        "    display(Image.fromarray(out))"
      ],
      "metadata": {
        "id": "BwkffNwDRfMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons à présent charger les datasets de train et de test."
      ],
      "metadata": {
        "id": "6cBWzOqdTfFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nous avons besoin de deux datasets: un dataset d'entrainement et un de validation\n",
        "test_dataset = MNIST_dataset(torchvision.datasets.MNIST(root = '/content/MNIST', download= True, train=False))\n",
        "train_dataset = MNIST_dataset(torchvision.datasets.MNIST(root = '/content/MNIST', download= True, train=True))"
      ],
      "metadata": {
        "id": "LUuY1jArQvAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5j2XyRhO6m5"
      },
      "source": [
        "Montrons ci-dessous quelques exemples d'images que l'on trouve dans MNIST. Chaque image est associé avec un label qui indique son contenu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJpdDeIrO6m5"
      },
      "outputs": [],
      "source": [
        "item_0, label_0 = test_dataset[0]\n",
        "item_52, label_52 = test_dataset[52]\n",
        "print(f\"LABEL : {label_0}\")\n",
        "show_elem(item_0)\n",
        "\n",
        "print(f\"LABEL : {label_52}\")\n",
        "show_elem(item_52)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75XL_j-BO6m5"
      },
      "source": [
        "## Exercice 1:\n",
        "\n",
        "Chercher la taille d'une image typique de MNIST. Par exemple la taille de l'image 48 du test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhL0_yfeO6m5"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice 2:\n",
        "\n",
        "Vous allez maintenant définir votre réseau.\n",
        "\n",
        "La classe de base pour tout réseau de neurones dans pytorch est [torch.nn.module](https://pytorch.org/docs/stable/nn.html). Quand vous définissez un réseau de neurones, ce dernier doit hériter de la classe torch.nn.module. Notez qu'un module peut contenir d'autres modules.\n",
        "\n",
        "Quand vous créer un nouveau modèle, vous devez lui définir une fonction forward qui déterminera les opeérations effectives faites par le modèle.\n",
        "\n",
        "Construisez un réseau convolutionnel effectuant les opérations suivantes:\n",
        "- Une convolution de taille 4 prenant une image contenant un canal en entrée et sortant une image avec 4 canaux\n",
        "- Une activation ReLU\n",
        "- Une convolution de taille 4 prenant une image contenant 4 canaux en entrée et sortant une image avec 4 canaux\n",
        "- Une autre activation ReLU\n",
        "- Un max pooling de taille 2\n",
        "- Une convertion du batch d'image obtenu, alors de taille BATCH_SIZE x 4 x 4 x 4 en un vecteur de taille BATCH_SIZE x 64\n",
        "- Une couche Linéaire pleinement connectée sortant un vecteur de dimension 10\n",
        "\n",
        "N'hésitez pas à utiliser les documentations de [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [torch.nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu), [torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d) et [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) pour vous aider."
      ],
      "metadata": {
        "id": "1an8Frf_Plzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nous définissons une classe MonReseau qui hérite de torch.nn.module\n",
        "class MonReseau(torch.nn.Module):\n",
        "\n",
        "    # En python, __init__ est le constructeur de la classe\n",
        "    def __init__(self):\n",
        "\n",
        "        # Lorsque l'on crée un module, il faut toujours commencer par initialiser la classe torch.nn.module\n",
        "        super(MonReseau, self).__init__()\n",
        "\n",
        "        # Notre modéla possédera 5 modules\n",
        "        # VOTRE CODE ICI\n",
        "\n",
        "    # Un module doit toujours définir une fonction forward\n",
        "    def forward(self, x):\n",
        "        N, C, H, L = x.size()\n",
        "\n",
        "        # VOTRE CODE ici\n",
        "\n",
        "\n",
        "        return self.classifier(x)         # Renvoie le resultat"
      ],
      "metadata": {
        "id": "xj-dMe0tVlp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWyQQSXFO6m6"
      },
      "source": [
        "## Exercice 3: entrainons un réseau\n",
        "\n",
        "Vous allez à présent entrainer votre réseau de neurones. Commençons tout d'abord par créer une instance du réseau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_ZARB5wO6m6"
      },
      "outputs": [],
      "source": [
        "# ATTENTION: NE PAS RELANCER CETTE CELLULE APRES AVOIR EFFECTUE L'ENTRAINEMENT. Vous perdriez tout !\n",
        "mon_reseau = MonReseau()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11kkDM84O6m6"
      },
      "source": [
        "mon_reseau est un réseau de neurones qui prend en entrée une image noir et blanc de taille 28x28 et renvoie un vecteur de score de taille 10. Voyez plutôt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22vrqgUdO6m6"
      },
      "outputs": [],
      "source": [
        "# Fabriquons une image aléatoire et passons là dans mon_reseau\n",
        "x = torch.randn(1, 1, 28, 28)\n",
        "score_x = mon_reseau(x)\n",
        "print(score_x.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q48lGiXZO6m6"
      },
      "source": [
        "Ensuite nous avons besoin de mettre les datasets dans des DataLoader. En pytorch le DataLoader a deux fonctions:\n",
        "\n",
        "1) Regrouper les images du dataset en batch de plusieurs images\n",
        "\n",
        "2) Mélanger ces batchs et les donner dans un ordre aléatoire\n",
        "\n",
        "Fabriquons le DataLoader du dataset d'entrainement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eaUsKHvO6m6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHvEPbWKO6m6"
      },
      "source": [
        "Les arguments pour construire un data-loader sont les suivants:\n",
        "\n",
        "1) dataset que l'on souhaite charger\n",
        "\n",
        "2) batch_size : taille de chaque batch. Dans l'exemple chaque batch contidendra 4 images\n",
        "\n",
        "3) shuffle: True si les batchs doivent être mélangés\n",
        "\n",
        "De la même manière, créez test_loader, le DataLoader de la base de validation. Mais cette fois-ci, donnez lui un batch_size de 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlH3qnPYO6m6"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Anj0RUO6m6"
      },
      "source": [
        "À présent il nous faut une loss. On utilisera la cross entropy. Dans pytorch, la classe torch.nn.CrossEntropyLoss() combine en un seul module à la fois le softmax et la cross-entropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hfzD7_8O6m6"
      },
      "outputs": [],
      "source": [
        "loss_mode = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4RjKoIVO6m6"
      },
      "source": [
        "Pour finir, nous avons besoin d'un optimizer. En pytorch l'optimizer est la classe qui utilise les gradients déjà calculés après la rétro-propagation pour mettre à jour les poids du réseau de neurones.\n",
        "\n",
        "Nous prenons un SGD (Stochastic Gradient Descent) qui correspond à une descente de gradient classique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9mWLDuEO6m6"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(mon_reseau.parameters(), lr=2e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWt8g2SgO6m6"
      },
      "source": [
        "Le paramètre lr que vous pouvez voir s'appelle le **learning rate**: il correspond à la taille du pas fait lors de la descente de gradient. Plus le **learning rate** est élevé, plus le réseau apprend vite, mais plus ses performances à la convergence seront approximatives.\n",
        "\n",
        "Nous pouvons à présent entrainer le réseau ! Ça va prendre un peu de temps (environ 5min selon les machines), c'est normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__QDFsWDO6m7"
      },
      "outputs": [],
      "source": [
        "# Nous parcourir 3 fois le dataset d'entrainement, on dit que l'on fait 3 epochs\n",
        "for epoch in range(3):\n",
        "    avg_loss_train = 0\n",
        "    n_steps_train = 0\n",
        "\n",
        "    # Phase d'entrainement\n",
        "    # Nous mettons le réseau en mode train()\n",
        "    mon_reseau.train()\n",
        "\n",
        "    # On parcourt le dataset d'entrainement\n",
        "    for data, label in train_loader:\n",
        "\n",
        "        # On commence par remettre tous les gradients à zéro\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Puis on calcule le vecteur de score du réseau\n",
        "        score = mon_reseau(data)\n",
        "\n",
        "        # On compare ce vecteur score avec les labels des images pour obetnir une loss\n",
        "        loss = loss_mode(score, label)\n",
        "\n",
        "        # À partir de la loss on fait la rétropropagation du gradient.\n",
        "        # Pytorch devine tout seul les gradients à calculer ! Pas besoin de les lui dire.\n",
        "        loss.backward()\n",
        "\n",
        "        # Maintenant que les gradients sont calculés on peut mettre à jour les paramètres du model\n",
        "        # Cette opération se fait sur l'optimizer avec .step()\n",
        "        optimizer.step()\n",
        "\n",
        "        # On met à jour la loss moyenne calculée lors de l'entrainment pour avoir une idée de ce qu'il se\n",
        "        # passe\n",
        "        avg_loss_train = avg_loss_train + loss\n",
        "        n_steps_train = n_steps_train + 1\n",
        "\n",
        "    print(f\"Epoch {epoch} loss train = {avg_loss_train / n_steps_train}\")\n",
        "\n",
        "    # Phase de test\n",
        "    # Nous mettons le réseau en mode eval()\n",
        "    mon_reseau.eval()\n",
        "\n",
        "    avg_loss_test = 0\n",
        "    n_steps_test = 0\n",
        "\n",
        "    for data, label in test_loader:\n",
        "\n",
        "        # Ici pas de gradient: nous voulons juste calculer la loss et la précision du modèle\n",
        "        score = mon_reseau(data)\n",
        "        loss = loss_mode(score, label)\n",
        "        avg_loss_test= avg_loss_test + loss\n",
        "        n_steps_test =n_steps_test +1\n",
        "\n",
        "    print(f\"Epoch {epoch} loss test = {avg_loss_test / n_steps_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2as7F6KiO6m7"
      },
      "source": [
        "Maintenant nous aimerions savoir si le réseau a appris quelque chose. Faisons un test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekbL4xtYO6m7"
      },
      "outputs": [],
      "source": [
        "image_test_3, label_test_3 = test_dataset[3]\n",
        "image_test_4, label_test_4 = test_dataset[4]\n",
        "image_test_25, label_test_25 = test_dataset[25]\n",
        "show_elem(image_test_3)\n",
        "show_elem(image_test_4)\n",
        "show_elem(image_test_25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uzDLxHnO6m7"
      },
      "outputs": [],
      "source": [
        "# On met les image_test dans un format lisible pour le réseau\n",
        "image_test_3 = image_test_3.view(1, 1, 28, 28)\n",
        "image_test_4 = image_test_4.view(1, 1, 28, 28)\n",
        "image_test_25 = image_test_25.view(1, 1, 28, 28)\n",
        "\n",
        "# On les concatene en batch\n",
        "batch_test = torch.cat([image_test_3, image_test_4, image_test_25], dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Msu4GQ0O6m7"
      },
      "source": [
        "1) Calculez score_test le vecteur de score de batch_test donné par mon_reseau()\n",
        "\n",
        "2) Calculez index_test, certitude_test l'index et la certitudes des predictions (pensez à [torch.nn.functional.softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaqFLPr5O6m7"
      },
      "outputs": [],
      "source": [
        "# Votre Code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M6rfdHDO6m7"
      },
      "source": [
        "## Exercice 3 (BONUS):\n",
        "\n",
        "Trois exemples ce n'est **pas suffisant** pour savoir si un réseau marche ou non. Pour le savoir, il faut calculer le taux d'erreur sur l'ensemble du dataset de test.\n",
        "\n",
        "La fonction ci-dessous calcule le taux d'erreur sur un batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ05QAowO6m7"
      },
      "outputs": [],
      "source": [
        "def get_error_rate(model, input_batch, input_label):\n",
        "    r\"\"\"\n",
        "    Calcule le taux d'erreur du modèle donné sur le batch donné.\n",
        "    Arguments:\n",
        "    model : le model à appliquer\n",
        "    input_batch : un batch d'images au format N x C x H x L\n",
        "    input_label : un tensor de labels au format N\n",
        "    \"\"\"\n",
        "    # On calcule le vecteur de score\n",
        "    # Score est de taille N x10\n",
        "    scores = model(input_batch)\n",
        "\n",
        "    # On cherche l'element du réseau\n",
        "    # max_index est de taille N\n",
        "    max_score, max_index = scores.max(dim=1)\n",
        "\n",
        "    N = max_index.size(0)\n",
        "\n",
        "    # On regarde toutes les fois ou le score maximal ne correspond pas au label\n",
        "    #print(max_index, input_label)\n",
        "    is_false =  max_index != input_label\n",
        "\n",
        "    # On retourne le taux d'erreur:\n",
        "    return is_false.sum() / float(N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xgly2tJO6m7"
      },
      "source": [
        "Utilisez la fonction get_error_rate pour calculer le taux d'erreur moyen sur l'ensemble du dataset de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jP0WbWbO6m7"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}